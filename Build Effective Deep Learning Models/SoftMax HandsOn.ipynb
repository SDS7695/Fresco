{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the first handson!!!\n",
    "- In this handson you will be building an deep neural network network for multiclass classification using softmax regression.\n",
    "- You will also be implementing minibatch gradient descent to train you network\n",
    "- Follow the instruction provided for cell to write the code in each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- The data is provided as file named 'data.csv'.\n",
    "- The data has two features feature1 and feature2 and one targer variable which is a binary value\n",
    "- Using pandas read the csv file and assign the resulting dataframe to variable 'data'   \n",
    "- for example if file name is 'xyz.csv' read file as **pd.read_csv('xyz.csv')**\n",
    "- Packages to import: **pandas** (to read csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2  class\n",
      "0  0.986038  0.065523    3.0\n",
      "1 -1.460077  1.651296    3.0\n",
      "2 -0.896203 -1.279647    3.0\n",
      "3  0.094218 -5.933941    2.0\n",
      "4  2.864974 -8.743053    1.0\n"
     ]
    }
   ],
   "source": [
    "###start code here\n",
    "import pandas as pd                 #import pandas \n",
    "data = pd.read_csv('data.csv')\n",
    "### end code(aprox 2 lines)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract feature1 and feature2 values from dataframe 'df' and assign it to variable 'X'\n",
    "- Extract target variable 'traget' and assign it to variable 'y'.  \n",
    "Hint:\n",
    " - Use .values to exract values from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target labels:  [0.0, 1.0, 2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "#Start Code\n",
    "X = data[['feature1', 'feature2']].values                                   #Extract feature1 and feature2 values\n",
    "Y =  data['class'].values                                         #Extract target values\n",
    "#End code\n",
    "print(\"target labels: \", list(set(Y)))\n",
    "\n",
    "assert X.shape == (2000, 2)\n",
    "assert Y.shape == (2000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are four target lables mapped as 0,1,2 and 3\n",
    "- Run the below cell to visualize the data in x-y plane. (visualization code has been written for you)\n",
    "- The blue spots corresponds to target value 0, green corresponds to 1, red corresponds to 2 and yellow to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "colors=['blue','green','red', 'yellow']\n",
    "cmap = matplotlib.colors.ListedColormap(colors)\n",
    "#Plot the figure\n",
    "plt.figure()\n",
    "plt.title('Non-linearly separable classes')\n",
    "plt.scatter(X[:,0], X[:,1], c=Y,\n",
    "           marker= 'o', s=50,cmap=cmap,alpha = 0.5 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow package as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " import tensorflow as tf                #import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- perform one hot encoding on target Y. Use tensorflow's one_hot() function, make sure mapping is done column-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  [0.0, 1.0, 2.0, 3.0]\n",
      "\n",
      "first five rows of target Y:\n",
      " [3. 3. 3. 2. 1.]\n",
      "\n",
      "first five rows of target Y_onehot:\n",
      " [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 1. 1. 0. 0.]]\n",
      "X dimension:(2000, 2) ,Y_onehot dimension:(4, 2000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "labels = list(set(Y))\n",
    "#Start Code\n",
    "depth = len(np.unique(Y))                   #number of unique labels\n",
    "#End code\n",
    "print(\"labels: \", labels)\n",
    "with tf.Session() as sess:\n",
    "###start code here\n",
    "    YtrainOneHot = tf.one_hot(Y, depth, axis = 0) # columnwise: axis = 0, axis=-1 row-wise\n",
    "    Y_onehot = sess.run(YtrainOneHot)\n",
    "###End code\n",
    "assert Y_onehot.shape == (4, 2000)\n",
    "\n",
    "print(\"\\nfirst five rows of target Y:\\n\", Y[:5])\n",
    "print(\"\\nfirst five rows of target Y_onehot:\\n\", Y_onehot[:,:5])\n",
    "print(\"X dimension:{} ,Y_onehot dimension:{}\".format(X.shape, Y_onehot.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to feed the network the input has to be of **shape (number of features, number of samples)** and target should be of shape **(1, number of samples)**\n",
    "- Transpose X and assign it to variable 'X_data'\n",
    "- target Y_onehot is already in shape, so just assign Y to variable Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Start code\n",
    "X_data = X.T\n",
    "Y_data = Y_onehot\n",
    "##End code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network dimension to have two input features, two hidden layers with 25 nodes each, 4 output nodes at final layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start code\n",
    "layer_dims = [2,25,25,4]\n",
    "#End code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function named placeholders to return two placeholders one for input data as A_0 and one for output data as Y.\n",
    "- Set the datatype of placeholders as float64\n",
    "- parameters - num_features\n",
    "- Returns - A_0 with shape (num_feature, None) and Y with shape(1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placeholders(num_features, num_classes):\n",
    "    A_0 = tf.placeholder(dtype = tf.float64, shape = ([num_features,None]))\n",
    "    Y = tf.placeholder(dtype = tf.float64, shape = ([num_classes,None]))\n",
    "    return A_0,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function named initialize_parameters_deep() to initialize weights and bias for each layer\n",
    "- Use tf.get_variable to initialise weights and bias, set datatype as float64\n",
    "- Make sure you are using xavier initialization for weigths and initialize bias to zeros\n",
    "- Parameters - layer_dims\n",
    "- Returns - dictionary of weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    tf.set_random_seed(1)\n",
    "    L = len(layer_dims)\n",
    "    parameters = {}\n",
    "    for l in range(1,L):\n",
    "        parameters['W' + str(l)] = tf.get_variable(\"W\" + str(l), shape=[layer_dims[l], layer_dims[l-1]], dtype = tf.float64,\n",
    "                                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "        parameters['b' + str(l)] = tf.get_variable(\"b\"+ str(l), shape = [layer_dims[l], 1], dtype= tf.float64, initializer= tf.zeros_initializer() )\n",
    "    return parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functon named linear_forward_prop() to define forward propagation for a given layer.\n",
    "- parameters: A_prev(output from previous layer), W(weigth matrix of current layer), b(bias vector for current layer),activation(type of activation to be used for out of current layer)  \n",
    "- returns: A(output from the current layer)\n",
    "- Use relu activation for hidden layers and for final output layer return the output unactivated i.e if activation is 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward_prop(A_prev,W,b, activation):\n",
    "    #Start code here \n",
    "    Z =     tf.add(tf.matmul(W, A_prev), b)   \n",
    "    if activation == \"softmax\":\n",
    "        A = Z\n",
    "    elif activation == \"relu\":\n",
    "        A = tf.nn.relu(Z)\n",
    "    return A\n",
    "   #End code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward propagation for entire network is defined for you as l_layer_forward(). We are not using any regularization technique here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_layer_forwardProp(A_0, parameters):\n",
    "    A = A_0\n",
    "    L = len(parameters)//2\n",
    "    for l in range(1,L):\n",
    "        A_prev = A\n",
    "        A = linear_forward_prop(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n",
    "    A = linear_forward_prop(A, parameters['W' + str(L)], parameters['b' + str(L)], \"softmax\" )\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define cost function as final_cost()\n",
    "- The logits and target value has to be in shape (number of samples, number of class) for      \n",
    "softmax_cross_entropy_with_logits() function to calculate cost\n",
    "- since Z_final and Y are tensoflow object we are using tf.transpose() before feeding  softmax_cross_entropy_with_logits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_cost(Z_final, Y ):\n",
    "    logits = tf.transpose(Z_final)\n",
    "    labels = tf.transpose(Y)\n",
    "    ###Start code\n",
    "    cost = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)            #use tensorflow's softmax_cross_entropy to calculate cost\n",
    "    ###End code\n",
    "    return tf.reduce_mean(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function to generate mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def random_samples_minibatch(X, Y, batch_size, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "    m = X.shape[1]                                 #number of samples\n",
    "    num_batches = int(m/batch_size)                #number of batches derived from batch_size\n",
    "    indices = np.random.permutation(m)             # generate ramdom indicies\n",
    "    shuffle_X = X[:,indices]\n",
    "    shuffle_Y = Y[:,indices]\n",
    "    mini_batches = []\n",
    "    \n",
    "    #generate minibatch\n",
    "    for i in range(num_batches):\n",
    "        ##Start code here\n",
    "        X_batch = shuffle_X[:,i * batch_size:(i+1) * batch_size]\n",
    "        Y_batch = shuffle_Y[:,i * batch_size:(i+1) * batch_size]\n",
    "        ##End code\n",
    "        \n",
    "        assert X_batch.shape == (X.shape[0], batch_size)\n",
    "        assert Y_batch.shape == (Y.shape[0], batch_size)\n",
    "        \n",
    "        mini_batches.append((X_batch, Y_batch))\n",
    "    \n",
    "    #generate batch with remaining number of samples\n",
    "    if m % batch_size != 0:\n",
    "        ##Srart code here\n",
    "        X_batch = shuffle_X[:, (num_batches * batch_size):]\n",
    "        Y_batch = shuffle_Y[:, (num_batches * batch_size):]\n",
    "        ##Srart code here\n",
    "        mini_batches.append((X_batch, Y_batch))\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model to train the network using minibatch\n",
    "- parameters:\n",
    "  - X_train, Y_train: input and target data\n",
    "  - layer_dims: network configuration\n",
    "  - learning_rate\n",
    "  - num_iter: number of epoches\n",
    "  - mini_batch_size: number of samples to be considered in each minibatch\n",
    "- return: dictionary of trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_with_minibatch(X_train,Y_train, layer_dims, learning_rate, num_iter, mini_batch_size):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    num_features, num_samples = X_train.shape\n",
    "    num_classes = Y_train.shape[0]\n",
    "    A_0, Y = placeholders(num_features, num_classes)\n",
    "    parameters = initialize_parameters_deep(layer_dims)\n",
    "    Z_final = l_layer_forwardProp(A_0, parameters)\n",
    "    cost = final_cost(Z_final, Y)\n",
    "    train_net = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    seed = 1\n",
    "    num_minibatches = int(num_samples / mini_batch_size)\n",
    "    init = tf.global_variables_initializer()\n",
    "    costs = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_iter):\n",
    "            epoch_cost = 0\n",
    "            mini_batches = random_samples_minibatch(X_train, Y_train, mini_batch_size, seed) #generate array of minibatch using random_samples_minibatch()\n",
    "            seed = seed + 1\n",
    "            \n",
    "            #perform gradient descent for each mini-batch\n",
    "            for mini_batch in mini_batches: \n",
    "                ##Start code\n",
    "                X_batch, Y_batch = mini_batch\n",
    "                _,mini_batch_cost = sess.run([train_net, cost], feed_dict={A_0: X_batch, Y: Y_batch})\n",
    "                ##End code\n",
    "                \n",
    "                epoch_cost += mini_batch_cost/num_minibatches\n",
    "            if epoch % 1 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "            if epoch % 10 == 0:\n",
    "                print(epoch_cost)\n",
    "        with open('output.txt', 'w') as file:\n",
    "            file.write(\"cost = %f\" % costs[-1])\n",
    "        plt.ylim(0, max(costs), 0.0001)\n",
    "        plt.xlabel(\"epoches per 100\")\n",
    "        plt.ylabel(\"cost\")\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "        params = sess.run(parameters)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8797401636011671\n",
      "0.39547961779391055\n",
      "0.3395450359650262\n",
      "0.30608861826531714\n",
      "0.2880744663267645\n",
      "0.2753135010039041\n",
      "0.27045427985529763\n",
      "0.26571231209151247\n",
      "0.26219009614350147\n",
      "0.2633101463309519\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = model_with_minibatch(X.T, Y_onehot, layer_dims, 0.01, 100, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The function to predict the ouput has been defined for you.  \n",
    "- The function takes input and trained parameters and predict the output using forward propagation  \n",
    "- the arg_max function returns the index of largest probability value in out y of each sample  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, params):\n",
    "    with tf.Session() as sess:\n",
    "        Y = tf.arg_max(l_layer_forwardProp(X_train,params), dimension=0)\n",
    "        return sess.run(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next two cell to visualize the boundary predicted by the model (This takes slightly longer time for the plot to appear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary1( X, y, model):\n",
    "    plt.clf()\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n",
    "    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1   \n",
    "    colors=['blue','green','red', 'yellow']\n",
    "    cmap = matplotlib.colors.ListedColormap(colors)   \n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole grid\n",
    "    A = model(np.c_[xx.ravel(), yy.ravel()])\n",
    "    A = A.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, A, cmap=\"spring\")\n",
    "    plt.ylabel('x2')\n",
    "    plt.xlabel('x1')\n",
    "    plt.scatter(X[0, :], X[1, :], c=y, s=8,cmap=cmap)\n",
    "    plt.title(\"Decision Boundary\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-169da8fda595>:3: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n"
     ]
    }
   ],
   "source": [
    "plot_decision_boundary1(X_data,Y,lambda x: predict(x.T,params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
